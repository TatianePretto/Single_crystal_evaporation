{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data treatment \n",
    "Data cleaning, feature engineering, data evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import auto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 1-10 hours database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open the file\n",
    "Data_raw = pd.read_csv(r\"....\\DB_model1.csv\", \n",
    "                                delimiter = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning/Manipulation/Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of separated sizes, creating the seed area\n",
    "Data_raw ['Seed crystal mm2'] = (Data_raw['Seed Size A (mm)']*\n",
    "                                      Data_raw['Seed Size B (mm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing non-desired features from the raw data - categorical, constants, values obtained in the end and imaging related features\n",
    "Data_raw = Data_raw.drop(['Hotplate', 'Last Syringe Mass (g)',\n",
    "                            'Last Solution Mass (g)', 'Last Total Mass (g)',\n",
    "                            'All Deposited Crystals (g)', 'Total Infusion (g)', 'Total Evaporation (g)', \n",
    "                            'Estimated Last Concentration (wt.%)', 'Hotplate Temperature (oC)',\n",
    "                            'Syringe Diameter (mm)', 'Imaging Width (pixel)',\n",
    "                            'Imaging Height (pixel)', 'Shot Interval (sec)', 'Mask Radius (pixel)',\n",
    "                            'Scale (pixel/mm2)', 'B Bottom Threshold', 'G Bottom Threshold',\n",
    "                            'R Bottom Threshold', 'B Top Threshold', 'G Top Threshold',\n",
    "                            'R Top Threshold', 'L Smoothing Parameters 1',\n",
    "                            'L Smoothing Parameters 2', 'G Smoothing Parameters 1',\n",
    "                            'G Smoothing Parameters 2', 'Smoothed Growth Rate (mm/h)', 'Smoothed Length (mm)',\n",
    "                            'source', 'Unnamed: 0', 'source.1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "heatmap = sns.heatmap(Data_raw.corr(), vmin=-1, vmax=1, annot=False, cbar_kws={'shrink': 0.6}, \n",
    "                     cmap= cm.vik, square=True)\n",
    "\n",
    "heatmap.set_xticklabels(\n",
    "    heatmap.get_xticklabels(),\n",
    "    rotation=70,\n",
    "    horizontalalignment='right',\n",
    "    fontsize=18\n",
    ")\n",
    "heatmap.set_yticklabels(\n",
    "    heatmap.get_yticklabels(),\n",
    "    fontsize=18\n",
    ")\n",
    "colorbar = heatmap.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=16) \n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "file_name = r'...\\corr_plot_1_10_1st.png'\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non-desired features from the raw data - correlated and redundant features\n",
    "Data_raw = Data_raw.drop(['Crystal Size A (mm)', 'Crystal Size B (mm)', 'Crystal Size C (mm)', 'Number of Crystals',\n",
    "                            'integral e', 'Length (mm)', 'Kp', 'Ki', 'Kd', 'de/dt', 'e(t)',\n",
    "                            'Initial Infusion Rate (mL/h)', 'Total Infusion (mL)',\n",
    "                            'Initial Syringe Mass (g)', 'Initial Total Mass (g)',\n",
    "                            'Est-Mass (g)', 'Initial Concentration (wt.%)', 'Estimated Evaporation Rate (g/h)',\n",
    "                            'Seed crystal mm2', 'Seed Size A (mm)', 'Seed Size B (mm)', 'Seed Size C (mm)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_final = Data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "Data_final = Data_final.rename(columns=\n",
    "                                 {'Initial Solution Mass (g)':'Initial_Solution_Mass',\n",
    "                                  'Room Temperature (oC)':'Room_Temperature', \n",
    "                                  'Humidity (RH%)': 'Humidity',\n",
    "                                  'Evaporation Rate (g/h)': 'Evaporation_Rate',\n",
    "                                  'Ideal Growth Rate (mm/h)': 'Ideal_Growth_Rate', \n",
    "                                  'Time (h)': 'Time', \n",
    "                                  'Infusion Rate (mL/h)': 'Infusion_Rate',\n",
    "                                  'Area (mm2)': 'Area', \n",
    "                                  'Growth Rate (mm/h)': 'Growth_Rate', \n",
    "                                  'Estimated Concentration (wt.%)': 'Estimated_Concentration'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New order of columns\n",
    "new_order = ['Initial_Solution_Mass', 'Room_Temperature', 'Humidity',\n",
    "       'Evaporation_Rate', 'Ideal_Growth_Rate', 'Infusion_Rate', 'Time',\n",
    "       'Area', 'Growth_Rate', 'Estimated_Concentration']\n",
    "\n",
    "Data_final = Data_final.reindex(columns=new_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NA values and negative values from evaporation rate and estimated concentration\n",
    "Data_final = Data_final.dropna()\n",
    "Data_final = Data_final[Data_final['Evaporation_Rate'] >= 0]\n",
    "Data_final = Data_final[Data_final['Estimated_Concentration'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "heatmap = sns.heatmap(Data_final.corr(), vmin=-1, vmax=1, annot=False, cbar_kws={'shrink': 0.6}, \n",
    "                     cmap= cm.vik, square=True)\n",
    "\n",
    "heatmap.set_xticklabels(\n",
    "    heatmap.get_xticklabels(),\n",
    "    rotation=70,\n",
    "    horizontalalignment='right',\n",
    "    fontsize=22\n",
    ")\n",
    "heatmap.set_yticklabels(\n",
    "    heatmap.get_yticklabels(),\n",
    "    fontsize=22\n",
    ")\n",
    "colorbar = heatmap.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=18) \n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "file_name = r'...\\corr_plot_1_10_2st.png'\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models development/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from hyperopt import hp, fmin, tpe, space_eval, Trials\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x and y subsets\n",
    "x = Data_final.drop(['Evaporation_Rate'], axis=1)\n",
    "y = Data_final[['Evaporation_Rate']]\n",
    "\n",
    "np.random.seed(100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=25) # 75% training and 25% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### to optimize hyperparameters, do the lines below\n",
    "# Define the search space\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(1, 800)),\n",
    "    'max_features': hp.choice('max_features', [1.0, 'sqrt']),\n",
    "    'max_leaf_nodes': hp.choice('max_leaf_nodes', range(2, 500)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 10)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'min_weight_fraction_leaf': hp.choice('min_weight_fraction_leaf', [0.1])\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    dt = DecisionTreeRegressor(**params)\n",
    "    scores = cross_val_score(dt, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean()) \n",
    "    return rmse\n",
    "\n",
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=200, trials=trials)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = space_eval(space, best)\n",
    "\n",
    "# Create a Decision Tree regressor with the best hyperparameters\n",
    "dt = DecisionTreeRegressor(**best_params)\n",
    "scores = cross_val_score(dt, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = dt.predict(X_test)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimized model for decision trees\n",
    "# Create the parameter grid based on the results of random search - using hyperopt   --- decision trees\n",
    "best_params = {\n",
    "              'max_depth': 22, \n",
    "              'max_features':1.0, \n",
    "              'max_leaf_nodes': 119,\n",
    "              'min_weight_fraction_leaf': 0.1, \n",
    "              'min_samples_leaf': 7,\n",
    "              'min_samples_split': 8 \n",
    "}\n",
    "# Create a Decision Tree regressor with the best hyperparameters\n",
    "dt = DecisionTreeRegressor(**best_params)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = dt.predict(X_test)\n",
    "y_pred_train = dt.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "MAE_train_dt = pd.DataFrame(mean_absolute_error(y_train, y_pred_train, multioutput='raw_values'))\n",
    "RMSE_train_dt = pd.DataFrame(np.sqrt(mean_squared_error(y_train, y_pred_train, multioutput='raw_values')))\n",
    "R2_train_dt = pd.DataFrame(r2_score(y_train, y_pred_train, multioutput='raw_values'))\n",
    "train_metrics_dt = pd.concat([MAE_train_dt, RMSE_train_dt, R2_train_dt], axis='columns')\n",
    "train_metrics_dt.columns = ['MAE_train', 'RMSE_train', 'R2_train']\n",
    "print(train_metrics_dt)\n",
    "\n",
    "# Test metrics\n",
    "MAE_test_dt = pd.DataFrame(mean_absolute_error(y_test, y_pred, multioutput='raw_values'))\n",
    "RMSE_test_dt = pd.DataFrame(np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values')))\n",
    "R2_test_dt = pd.DataFrame(r2_score(y_test, y_pred, multioutput='raw_values'))\n",
    "test_metrics_dt = pd.concat([MAE_test_dt, RMSE_test_dt, R2_test_dt], axis='columns')\n",
    "test_metrics_dt.columns = ['MAE_test', 'RMSE_test', 'R2_test']\n",
    "print(test_metrics_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### to optimize hyperparameters, do the lines below\n",
    "# Define the search space\n",
    "space = {\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False]),\n",
    "    'max_depth': hp.choice('max_depth', range(1, 100)),\n",
    "    'max_features': hp.choice('max_features', [1.0, 'sqrt']),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 10)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 500))\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean()) \n",
    "    return rmse\n",
    "\n",
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=2, trials=trials)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = space_eval(space, best)\n",
    "\n",
    "# Create a Random Forest regressor with the best hyperparameters\n",
    "rf = RandomForestRegressor(**best_params)\n",
    "scores = cross_val_score(rf, X_train, y_train, scoring='neg_mean_squared_error')\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest optimized\n",
    " #### after defined the search space\n",
    "best_params = {\n",
    "    'bootstrap': False,\n",
    "    'max_depth': 30,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 2,\n",
    "    'min_samples_split': 4,\n",
    "    'n_estimators': 250,\n",
    "}\n",
    "\n",
    "# Create a Random Forest regressor with the best hyperparameters - hyperopt\n",
    "rf = RandomForestRegressor(**best_params)\n",
    "rf.fit(X_train, np.ravel(y_train))  \n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "MAE_train_rf = pd.DataFrame(mean_absolute_error(y_train, y_pred_train, multioutput='raw_values'))\n",
    "RMSE_train_rf = pd.DataFrame(np.sqrt(mean_squared_error(y_train, y_pred_train, multioutput='raw_values')))\n",
    "R2_train_rf = pd.DataFrame(r2_score(y_train, y_pred_train, multioutput='raw_values'))\n",
    "train_metrics_rf = pd.concat([MAE_train_rf, RMSE_train_rf, R2_train_rf], axis='columns')\n",
    "train_metrics_rf.columns = ['MAE_train', 'RMSE_train', 'R2_train']\n",
    "print(train_metrics_rf)\n",
    "\n",
    "# Test metrics\n",
    "MAE_test_rf = pd.DataFrame(mean_absolute_error(y_test, y_pred, multioutput='raw_values'))\n",
    "RMSE_test_rf = pd.DataFrame(np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values')))\n",
    "R2_test_rf = pd.DataFrame(r2_score(y_test, y_pred, multioutput='raw_values'))\n",
    "test_metrics_rf = pd.concat([MAE_test_rf, RMSE_test_rf, R2_test_rf], axis='columns')\n",
    "test_metrics_rf.columns = ['MAE_test', 'RMSE_test', 'R2_test']\n",
    "print(test_metrics_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### to optimize hyperparameters, do the lines below\n",
    "# Define the search space\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(5, 50)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.03, 0.08),\n",
    "    'n_estimators': hp.choice('n_estimators', range(400,1000)),\n",
    "    'gamma': hp.uniform('gamma', 0.3, 0.7),\n",
    "    'min_child_weight': hp.choice('min_child_weight', range(5, 15)),\n",
    "    'subsample': hp.uniform('subsample', 0.1, 0.8),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.8)\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    xgb_reg = xgb.XGBRegressor(**params, random_state=42)\n",
    "    scores = cross_val_score(xgb_reg, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean())\n",
    "    return rmse \n",
    "\n",
    "\n",
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = space_eval(space, best)\n",
    "\n",
    "# Create a Decision Tree regressor with the best hyperparameters\n",
    "xgb = xgb.XGBRegressor(**best_params)\n",
    "scores = cross_val_score(xgb, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_train = xgb.predict(X_train)\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost optimized with hyperopt\n",
    "\n",
    "best_params = {\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.04,\n",
    "    'n_estimators': 1000,\n",
    "    'gamma': 0.1,\n",
    "    'min_child_weight': 10,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'lambda': 1,\n",
    "    'alpha': 0\n",
    "}\n",
    "\n",
    "# Create a Random Forest regressor with the best hyperparameters - hyperopt\n",
    "xgb = xgb.XGBRegressor(**best_params)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_train = xgb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "MAE_train_xgb = pd.DataFrame(mean_absolute_error(y_train, y_pred_train, multioutput='raw_values'))\n",
    "RMSE_train_xgb = pd.DataFrame(np.sqrt(mean_squared_error(y_train, y_pred_train, multioutput='raw_values')))\n",
    "R2_train_xgb = pd.DataFrame(r2_score(y_train, y_pred_train, multioutput='raw_values'))\n",
    "train_metrics_xgb = pd.concat([MAE_train_xgb, RMSE_train_xgb, R2_train_xgb], axis='columns')\n",
    "train_metrics_xgb.columns = ['MAE_train', 'RMSE_train', 'R2_train']\n",
    "print(train_metrics_xgb)\n",
    "\n",
    "# Test metrics\n",
    "MAE_test_xgb = pd.DataFrame(mean_absolute_error(y_test, y_pred, multioutput='raw_values'))\n",
    "RMSE_test_xgb = pd.DataFrame(np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values')))\n",
    "R2_test_xgb = pd.DataFrame(r2_score(y_test, y_pred, multioutput='raw_values'))\n",
    "test_metrics_xgb = pd.concat([MAE_test_xgb, RMSE_test_xgb, R2_test_xgb], axis='columns')\n",
    "test_metrics_xgb.columns = ['MAE_test', 'RMSE_test', 'R2_test']\n",
    "print(test_metrics_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features importance - SHAP and PFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features importance by permutation - test set\n",
    "result = permutation_importance(dt, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "# Order importances and features names\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices]\n",
    "sorted_feature_names = [X_test.columns[i] for i in indices]\n",
    "\n",
    "# Colormap into colors list\n",
    "n_colors = len(sorted_importances) \n",
    "colors = [cm.vik(i / (n_colors - 1)) for i in range(n_colors)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "#plt.title(\"Permutation Feature Importance\")\n",
    "ax = sns.barplot(x=sorted_importances, y=sorted_feature_names, palette=colors)\n",
    "plt.xlabel(\"Importance\", fontsize = 26)\n",
    "plt.ylabel(\"Feature\", fontsize = 26)\n",
    "plt.xticks(fontsize=26) \n",
    "plt.yticks(fontsize=30) \n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "\n",
    "# Name file\n",
    "file_name = r'...\\feat_imp_DT.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP plot\n",
    "\n",
    "# Random 1000 samples on test set\n",
    "N = 1000\n",
    "X_sample = X_test.sample(n=N, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(dt, data=X_test)\n",
    "\n",
    "shap_values = explainer.shap_values(X_sample, check_additivity=False)\n",
    "\n",
    "feature_names = X_test.columns.astype(str)\n",
    "\n",
    "# Create shap plot\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=False, cmap=cm.vik)\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "# Name file\n",
    "file_name = r'...\\Shap_DT_1_10.png'\n",
    "\n",
    "plt.gcf().set_size_inches(14, 8) \n",
    "\n",
    "plt.xticks(fontsize=22, color = 'black')          \n",
    "plt.yticks(fontsize=32, fontweight=500, color = 'black')\n",
    "plt.xlabel('SHAP value', fontsize = 25)  \n",
    "\n",
    "colorbar = plt.gcf().axes[-1]  \n",
    "colorbar.tick_params(labelsize=20)  \n",
    "colorbar.set_ylabel('Feature Value', fontsize=22)  \n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features importance by permutation - test set\n",
    "result = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "# Order importances and features names\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices]\n",
    "sorted_feature_names = [X_test.columns[i] for i in indices]\n",
    "\n",
    "# Colormap into colors list\n",
    "n_colors = len(sorted_importances) \n",
    "colors = [cm.vik(i / (n_colors - 1)) for i in range(n_colors)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "#plt.title(\"Permutation Feature Importance\")\n",
    "ax = sns.barplot(x=sorted_importances, y=sorted_feature_names, palette=colors)\n",
    "plt.xlabel(\"Importance\", fontsize = 26)\n",
    "plt.ylabel(\"Feature\", fontsize = 26)\n",
    "plt.xticks(fontsize=26) \n",
    "plt.yticks(fontsize=30) \n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "\n",
    "# Name file\n",
    "file_name = r'...\\feat_imp_RF.png'\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP plot\n",
    "\n",
    "# Random 1000 samples on test set\n",
    "N = 1000\n",
    "X_sample = X_test.sample(n=N, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(rf, data=X_test)\n",
    "\n",
    "shap_values = explainer.shap_values(X_sample, check_additivity=False)\n",
    "\n",
    "feature_names = X_test.columns.astype(str)\n",
    "\n",
    "# Create shap plot\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=False, cmap=cm.vik)\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "# Name file\n",
    "file_name = r'...\\Shap_RF_1_10.png'\n",
    "\n",
    "plt.gcf().set_size_inches(14, 8) \n",
    "\n",
    "plt.xticks(fontsize=22, color = 'black')          \n",
    "plt.yticks(fontsize=32, fontweight=500, color = 'black')\n",
    "plt.xlabel('SHAP value', fontsize = 25)  \n",
    "\n",
    "colorbar = plt.gcf().axes[-1]  \n",
    "colorbar.tick_params(labelsize=20)  \n",
    "colorbar.set_ylabel('Feature Value', fontsize=22)  \n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most important feature --- based on shap values\n",
    "important_feature_index = np.abs(shap_values.values).mean(axis=0).argsort()[-1]\n",
    "\n",
    "shap.plots.scatter(shap_values[:, important_feature_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependence Plot -- desired feature to analyze\n",
    "feature_to_plot = 'Initial_Solution_Mass'  \n",
    "\n",
    "shap.dependence_plot(feature_to_plot, shap_values, X_sample, feature_names=feature_names)\n",
    "#shap.plots.scatter(shap_values[:, important_feature_index])\n",
    "\n",
    "dependence_file_name = r'...\\Shap_Dependence_Plot.png'\n",
    "plt.savefig(dependence_file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features importance by permutation - test set\n",
    "result = permutation_importance(xgb, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "# Order importances and features names\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices]\n",
    "sorted_feature_names = [X_test.columns[i] for i in indices]\n",
    "\n",
    "# Colormap into colors list\n",
    "n_colors = len(sorted_importances) \n",
    "colors = [cm.vik(i / (n_colors - 1)) for i in range(n_colors)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "#plt.title(\"Permutation Feature Importance\")\n",
    "ax = sns.barplot(x=sorted_importances, y=sorted_feature_names, palette=colors)\n",
    "plt.xlabel(\"Importance\", fontsize = 26)\n",
    "plt.ylabel(\"Feature\", fontsize = 26)\n",
    "plt.xticks(fontsize=26) \n",
    "plt.yticks(fontsize=30) \n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "\n",
    "# Name file\n",
    "file_name = r'...\\feat_imp_XGB.png'\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP plot\n",
    "\n",
    "# Random 1000 samples on test set\n",
    "N = 1000\n",
    "X_sample = X_test.sample(n=N, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb, data=X_test)\n",
    "\n",
    "shap_values = explainer.shap_values(X_sample, check_additivity=False)\n",
    "\n",
    "feature_names = X_test.columns.astype(str)\n",
    "\n",
    "# Create shap plot\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=False, cmap=cm.vik)\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "# Name file\n",
    "file_name = r'...\\Shap_XGB_1_10.png'\n",
    "\n",
    "plt.gcf().set_size_inches(14, 8) \n",
    "\n",
    "plt.xticks(fontsize=22, color = 'black')          \n",
    "plt.yticks(fontsize=32, fontweight=500, color = 'black')\n",
    "plt.xlabel('SHAP value', fontsize = 25)  \n",
    "\n",
    "colorbar = plt.gcf().axes[-1]  \n",
    "colorbar.tick_params(labelsize=20)  \n",
    "colorbar.set_ylabel('Feature Value', fontsize=22)  \n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most important feature - based on shap values\n",
    "important_feature_index = np.abs(shap_values.values).mean(axis=0).argsort()[-1]\n",
    "\n",
    "shap.plots.scatter(shap_values[:, important_feature_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependence plot - specific feature\n",
    "feature_to_plot = 'Initial_Solution_Mass'\n",
    "shap.dependence_plot(feature_to_plot, shap_values, X_sample, feature_names=feature_names, cmap=cm.vik)\n",
    "#shap.plots.scatter(shap_values[:, important_feature_index])\n",
    "shap.initjs()\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "# Name file\n",
    "file_name = r'...Shap_Dependence_Plot_RF.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parity plots - Decision trees, Random forest, and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity - DT\n",
    "# Colors for plot\n",
    "colors = cm.vik\n",
    "train_color_index = 0.1\n",
    "test_color_index = 0.87\n",
    "train_color = colors(train_color_index)\n",
    "test_color = colors(test_color_index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot - train\n",
    "ax.scatter(y_train, y_pred_train, color=train_color, s=30, label='Train set')\n",
    "\n",
    "# Scatter plot - test\n",
    "ax.scatter(y_test, y_pred, color=test_color, s=30, label='Test set')\n",
    "\n",
    "# Diagonal line\n",
    "ax.plot([min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        [min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        color='black', linestyle='--')\n",
    "\n",
    "# Lables\n",
    "ax.set_ylabel('Predicted values', fontsize=25)\n",
    "ax.set_xlabel('True Values', fontsize=25)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "import matplotlib.ticker as ticker\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax.legend(fontsize=26, frameon = False, loc='upper left')\n",
    "\n",
    "# Name file\n",
    "file_name = r'...\\pred_evap_parity_DT_1_10.png'\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity - RF\n",
    "# Colors for plot\n",
    "colors = cm.vik\n",
    "train_color_index = 0.1\n",
    "test_color_index = 0.87\n",
    "train_color = colors(train_color_index)\n",
    "test_color = colors(test_color_index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot - train\n",
    "ax.scatter(y_train, y_pred_train, color=train_color, s=30, label='Train set')\n",
    "\n",
    "# Scatter plot - test\n",
    "ax.scatter(y_test, y_pred, color=test_color, s=30, label='Test set')\n",
    "\n",
    "# Diagonal line\n",
    "ax.plot([min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        [min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        color='black', linestyle='--')\n",
    "\n",
    "# Lables\n",
    "ax.set_ylabel('Predicted values', fontsize=25)\n",
    "ax.set_xlabel('True Values', fontsize=25)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "import matplotlib.ticker as ticker\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax.legend(fontsize=26, frameon = False, loc='upper left')\n",
    "\n",
    "# Name file\n",
    "file_name = r'...\\pred_evap_parity_RF_1_10.png'\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity - XGB\n",
    "# Colors for plot\n",
    "colors = cm.vik\n",
    "train_color_index = 0.1\n",
    "test_color_index = 0.87\n",
    "train_color = colors(train_color_index)\n",
    "test_color = colors(test_color_index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot - train\n",
    "ax.scatter(y_train, y_pred_train, color=train_color, s=30, label='Train set')\n",
    "\n",
    "# Scatter plot - test\n",
    "ax.scatter(y_test, y_pred, color=test_color, s=30, label='Test set')\n",
    "\n",
    "# Diagonal line\n",
    "ax.plot([min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        [min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        color='black', linestyle='--')\n",
    "\n",
    "# Lables\n",
    "ax.set_ylabel('Predicted values', fontsize=25)\n",
    "ax.set_xlabel('True Values', fontsize=25)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "import matplotlib.ticker as ticker\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax.legend(fontsize=26, frameon = False, loc='upper left')\n",
    "\n",
    "# Name file\n",
    "file_name = r'...\\pred_evap_parity_XGB_1_10.png'\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
