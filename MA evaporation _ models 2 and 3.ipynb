{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import auto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call database 10-20 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open the file\n",
    "Data_raw = pd.read_csv(r\"Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\DB_model2.csv\", \n",
    "                                delimiter = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call database 20-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open the file\n",
    "Data_raw_20_e = pd.read_csv(r\"Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\DB_model3.csv\", \n",
    "                                delimiter = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 10-20 hours database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of separated sizes, creating the seed area\n",
    "Data_raw ['Seed crystal mm2'] = (Data_raw['Seed Size A (mm)']*\n",
    "                                      Data_raw['Seed Size B (mm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing non-desired features from the raw data - categorical, constants, values obtained in the end and imaging related features\n",
    "Data_raw = Data_raw.drop(['Hotplate', 'Last Syringe Mass (g)',\n",
    "                            'Last Solution Mass (g)', 'Last Total Mass (g)',\n",
    "                            'All Deposited Crystals (g)', 'Total Infusion (g)', 'Total Evaporation (g)', \n",
    "                            'Estimated Last Concentration (wt.%)', 'Hotplate Temperature (oC)',\n",
    "                            'Syringe Diameter (mm)', 'Imaging Width (pixel)',\n",
    "                            'Imaging Height (pixel)', 'Shot Interval (sec)', 'Mask Radius (pixel)',\n",
    "                            'Scale (pixel/mm2)', 'B Bottom Threshold', 'G Bottom Threshold',\n",
    "                            'R Bottom Threshold', 'B Top Threshold', 'G Top Threshold',\n",
    "                            'R Top Threshold', 'L Smoothing Parameters 1',\n",
    "                            'L Smoothing Parameters 2', 'G Smoothing Parameters 1',\n",
    "                            'G Smoothing Parameters 2', 'Smoothed Growth Rate (mm/h)', 'Smoothed Length (mm)',\n",
    "                            'source', 'Unnamed: 0', 'source.1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot\n",
    "plt.figure(figsize=(10,8))\n",
    "heatmap = sns.heatmap(Data_raw.corr(), vmin=-1, vmax=1, annot=False, \n",
    "                    cmap= cm.vik, #'viridis', #cmocean.cm.matter,\n",
    "                    square=True)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(),\n",
    "                   rotation=45,\n",
    "                   horizontalalignment='right')\n",
    "# Name file\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\corr_plot_10_20_1st.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non-desired features from the raw data - correlated and redundant features\n",
    "Data_raw = Data_raw.drop(['Crystal Size A (mm)', 'Crystal Size B (mm)', 'Crystal Size C (mm)', 'Number of Crystals',\n",
    "                            'integral e', 'Length (mm)', 'Kp', 'Ki', 'Kd', 'de/dt', 'e(t)',\n",
    "                            'Initial Infusion Rate (mL/h)', 'Total Infusion (mL)',\n",
    "                            'Initial Syringe Mass (g)', 'Initial Total Mass (g)',\n",
    "                            'Est-Mass (g)', 'Initial Concentration (wt.%)', 'Estimated Evaporation Rate (g/h)',\n",
    "                            'Seed crystal mm2', 'Seed Size A (mm)', 'Seed Size B (mm)', 'Seed Size C (mm)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_final = Data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "Data_final = Data_final.rename(columns=\n",
    "                                 {'Initial Solution Mass (g)':'Initial_Solution_Mass',\n",
    "                                  'Room Temperature (oC)':'Room_Temperature', \n",
    "                                  'Humidity (RH%)': 'Humidity',\n",
    "                                  'Evaporation Rate (g/h)': 'Evaporation_Rate',\n",
    "                                  'Ideal Growth Rate (mm/h)': 'Ideal_Growth_Rate', \n",
    "                                  'Time (h)': 'Time', \n",
    "                                  'Infusion Rate (mL/h)': 'Infusion_Rate',\n",
    "                                  'Area (mm2)': 'Area', \n",
    "                                  'Growth Rate (mm/h)': 'Growth_Rate', \n",
    "                                  'Estimated Concentration (wt.%)': 'Estimated_Concentration'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New order of columns\n",
    "new_order = ['Initial_Solution_Mass', 'Room_Temperature', 'Humidity',\n",
    "       'Evaporation_Rate', 'Ideal_Growth_Rate', 'Infusion_Rate', 'Time',\n",
    "       'Area', 'Growth_Rate', 'Estimated_Concentration']\n",
    "\n",
    "Data_final = Data_final.reindex(columns=new_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NA values and negative values from evaporation rate and estimated concentration\n",
    "Data_final = Data_final.dropna()\n",
    "Data_final = Data_final[Data_final['Evaporation_Rate'] >= 0]\n",
    "Data_final = Data_final[Data_final['Estimated_Concentration'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot\n",
    "plt.figure(figsize=(10,8))\n",
    "heatmap = sns.heatmap(Data_raw.corr(), vmin=-1, vmax=1, annot=False, \n",
    "                    cmap= cm.vik,\n",
    "                    square=True)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(),\n",
    "                   rotation=45,\n",
    "                   horizontalalignment='right')\n",
    "\n",
    "# Name file\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\corr_plot_10_20_2nd.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models development/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from hyperopt import hp, fmin, tpe, space_eval, Trials\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x and y subsets\n",
    "x = Data_final.drop(['Evaporation_Rate'], axis=1)\n",
    "y = Data_final[['Evaporation_Rate']]\n",
    "\n",
    "np.random.seed(100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=25) # 75% training and 25% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### to optimize hyperparameters, do the lines below\n",
    "# Define the search space\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(1, 800)),\n",
    "    'max_features': hp.choice('max_features', [1.0, 'sqrt']),\n",
    "    'max_leaf_nodes': hp.choice('max_leaf_nodes', range(2, 500)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 10)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'min_weight_fraction_leaf': hp.choice('min_weight_fraction_leaf', [0.1])\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    dt = DecisionTreeRegressor(**params)\n",
    "    scores = cross_val_score(dt, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean())\n",
    "    return rmse\n",
    "\n",
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=200, trials=trials)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = space_eval(space, best)\n",
    "\n",
    "# Create a Decision Tree regressor with the best hyperparameters\n",
    "dt = DecisionTreeRegressor(**best_params)\n",
    "scores = cross_val_score(dt, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = dt.predict(X_test)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimized model for decision trees\n",
    "# Create the parameter grid based on the results of random search - using hyperopt   --- decision trees\n",
    "best_params = {\n",
    "              'max_depth': 22, \n",
    "              'max_features':1.0, \n",
    "              'max_leaf_nodes': 119,\n",
    "              'min_weight_fraction_leaf': 0.1, \n",
    "              'min_samples_leaf': 7,\n",
    "              'min_samples_split': 8 \n",
    "}\n",
    "# Create a Decision Tree regressor with the best hyperparameters\n",
    "dt = DecisionTreeRegressor(**best_params)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = dt.predict(X_test)\n",
    "y_pred_train = dt.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "MAE_train_dt = pd.DataFrame(mean_absolute_error(y_train, y_pred_train, multioutput='raw_values'))\n",
    "RMSE_train_dt = pd.DataFrame(np.sqrt(mean_squared_error(y_train, y_pred_train, multioutput='raw_values')))\n",
    "R2_train_dt = pd.DataFrame(r2_score(y_train, y_pred_train, multioutput='raw_values'))\n",
    "train_metrics_dt = pd.concat([MAE_train_dt, RMSE_train_dt, R2_train_dt], axis='columns')\n",
    "train_metrics_dt.columns = ['MAE_train', 'RMSE_train', 'R2_train']\n",
    "print(train_metrics_dt)\n",
    "\n",
    "# Test metrics\n",
    "MAE_test_dt = pd.DataFrame(mean_absolute_error(y_test, y_pred, multioutput='raw_values'))\n",
    "RMSE_test_dt = pd.DataFrame(np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values')))\n",
    "R2_test_dt = pd.DataFrame(r2_score(y_test, y_pred, multioutput='raw_values'))\n",
    "test_metrics_dt = pd.concat([MAE_test_dt, RMSE_test_dt, R2_test_dt], axis='columns')\n",
    "test_metrics_dt.columns = ['MAE_test', 'RMSE_test', 'R2_test']\n",
    "print(test_metrics_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### to optimize hyperparameters, do the lines below\n",
    "# Define the search space\n",
    "space = {\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False]),\n",
    "    'max_depth': hp.choice('max_depth', range(1, 100)),\n",
    "    'max_features': hp.choice('max_features', [1.0, 'sqrt']),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 10)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 500))\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean()) \n",
    "    return rmse\n",
    "\n",
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=2, trials=trials)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = space_eval(space, best)\n",
    "\n",
    "# Create a Random Forest regressor with the best hyperparameters\n",
    "rf = RandomForestRegressor(**best_params)\n",
    "scores = cross_val_score(rf, X_train, y_train, scoring='neg_mean_squared_error')\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest optimized\n",
    " #### after defined the search space\n",
    "best_params = {\n",
    "    'bootstrap': False,\n",
    "    'max_depth': 30,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 2,\n",
    "    'min_samples_split': 4,\n",
    "    'n_estimators': 250,\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(**best_params)\n",
    "rf.fit(X_train, np.ravel(y_train)) \n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "MAE_train_rf = pd.DataFrame(mean_absolute_error(y_train, y_pred_train, multioutput='raw_values'))\n",
    "RMSE_train_rf = pd.DataFrame(np.sqrt(mean_squared_error(y_train, y_pred_train, multioutput='raw_values')))\n",
    "R2_train_rf = pd.DataFrame(r2_score(y_train, y_pred_train, multioutput='raw_values'))\n",
    "train_metrics_rf = pd.concat([MAE_train_rf, RMSE_train_rf, R2_train_rf], axis='columns')\n",
    "train_metrics_rf.columns = ['MAE_train', 'RMSE_train', 'R2_train']\n",
    "print(train_metrics_rf)\n",
    "\n",
    "# Test metrics\n",
    "MAE_test_rf = pd.DataFrame(mean_absolute_error(y_test, y_pred, multioutput='raw_values'))\n",
    "RMSE_test_rf = pd.DataFrame(np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values')))\n",
    "R2_test_rf = pd.DataFrame(r2_score(y_test, y_pred, multioutput='raw_values'))\n",
    "test_metrics_rf = pd.concat([MAE_test_rf, RMSE_test_rf, R2_test_rf], axis='columns')\n",
    "test_metrics_rf.columns = ['MAE_test', 'RMSE_test', 'R2_test']\n",
    "print(test_metrics_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperopt\n",
    "####### to optimize hyperparameters, do the lines below\n",
    "# Define the search space\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(5, 50)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.03, 0.08),\n",
    "    'n_estimators': hp.choice('n_estimators', range(400,1000)),\n",
    "    'gamma': hp.uniform('gamma', 0.3, 0.7),\n",
    "    'min_child_weight': hp.choice('min_child_weight', range(5, 15)),\n",
    "    'subsample': hp.uniform('subsample', 0.1, 0.8),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.8)\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    xgb_reg = xgb.XGBRegressor(**params, random_state=42)\n",
    "    scores = cross_val_score(xgb_reg, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean()) \n",
    "    return rmse \n",
    "\n",
    "\n",
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = space_eval(space, best)\n",
    "\n",
    "# Create a Decision Tree regressor with the best hyperparameters\n",
    "xgb = xgb.XGBRegressor(**best_params)\n",
    "scores = cross_val_score(xgb, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_train = xgb.predict(X_train)\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost optimized with hyperopt\n",
    "\n",
    "best_params = {\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.04,\n",
    "    'n_estimators': 1000,\n",
    "    'gamma': 0.1,\n",
    "    'min_child_weight': 10,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'lambda': 1,\n",
    "    'alpha': 0\n",
    "}\n",
    "\n",
    "# Create a Random Forest regressor with the best hyperparameters - hyperopt\n",
    "xgb = xgb.XGBRegressor(**best_params)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_train = xgb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "MAE_train_xgb = pd.DataFrame(mean_absolute_error(y_train, y_pred_train, multioutput='raw_values'))\n",
    "RMSE_train_xgb = pd.DataFrame(np.sqrt(mean_squared_error(y_train, y_pred_train, multioutput='raw_values')))\n",
    "R2_train_xgb = pd.DataFrame(r2_score(y_train, y_pred_train, multioutput='raw_values'))\n",
    "train_metrics_xgb = pd.concat([MAE_train_xgb, RMSE_train_xgb, R2_train_xgb], axis='columns')\n",
    "train_metrics_xgb.columns = ['MAE_train', 'RMSE_train', 'R2_train']\n",
    "print(train_metrics_xgb)\n",
    "\n",
    "# Test metrics\n",
    "MAE_test_xgb = pd.DataFrame(mean_absolute_error(y_test, y_pred, multioutput='raw_values'))\n",
    "RMSE_test_xgb = pd.DataFrame(np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values')))\n",
    "R2_test_xgb = pd.DataFrame(r2_score(y_test, y_pred, multioutput='raw_values'))\n",
    "test_metrics_xgb = pd.concat([MAE_test_xgb, RMSE_test_xgb, R2_test_xgb], axis='columns')\n",
    "test_metrics_xgb.columns = ['MAE_test', 'RMSE_test', 'R2_test']\n",
    "print(test_metrics_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features importance by permutation\n",
    "result = permutation_importance(dt, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices]\n",
    "sorted_feature_names = [X_test.columns[i] for i in indices]\n",
    "\n",
    "n_colors = len(sorted_importances) \n",
    "colors = [cm.vik(i / (n_colors - 1)) for i in range(n_colors)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Permutation Feature Importance\")\n",
    "sns.barplot(x=sorted_importances, y=sorted_feature_names, palette=colors)\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "\n",
    "# Name file\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\feat_imp_DT_10_20.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP plot\n",
    "N = 1000\n",
    "X_sample = X_test.sample(n=N, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(dt, data=X_test)\n",
    "shap_values = explainer.shap_values(X_sample, check_additivity=False)\n",
    "feature_names = X_test.columns.astype(str)\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=False)\n",
    "shap.initjs()\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\Shap_DT_10_20.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance by permutation\n",
    "result = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices]\n",
    "sorted_feature_names = [X_test.columns[i] for i in indices]\n",
    "\n",
    "n_colors = len(sorted_importances)  \n",
    "colors = [cm.vik(i / (n_colors - 1)) for i in range(n_colors)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Permutation Feature Importance\")\n",
    "sns.barplot(x=sorted_importances, y=sorted_feature_names, palette=colors)\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\feat_imp_RF_10_20.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP plot\n",
    "N = 1000\n",
    "X_sample = X_test.sample(n=N, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(rf, data=X_test)\n",
    "\n",
    "shap_values = explainer.shap_values(X_sample, check_additivity=False)\n",
    "\n",
    "feature_names = X_test.columns.astype(str)\n",
    "\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=False)\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\Shap_RF_10_20.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance by permutation\n",
    "result = permutation_importance(xgb, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices]\n",
    "sorted_feature_names = [X_test.columns[i] for i in indices]\n",
    "\n",
    "n_colors = len(sorted_importances) \n",
    "colors = [cm.vik(i / (n_colors - 1)) for i in range(n_colors)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Permutation Feature Importance\")\n",
    "sns.barplot(x=sorted_importances, y=sorted_feature_names, palette=colors)\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\feat_imp_XGB_10_20.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP plot\n",
    "N = 1000\n",
    "X_sample = X_test.sample(n=N, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb, data=X_test)\n",
    "\n",
    "shap_values = explainer.shap_values(X_sample, check_additivity=False)\n",
    "\n",
    "feature_names = X_test.columns.astype(str)\n",
    "\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=False)\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\Shap_XGB_10_20.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parity plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity for DT\n",
    "colors = cm.vik\n",
    "train_color_index = 0.1\n",
    "test_color_index = 0.87\n",
    "train_color = colors(train_color_index)\n",
    "test_color = colors(test_color_index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(y_train, y_pred_train, color=train_color, s=30, label='Train set')\n",
    "\n",
    "ax.scatter(y_test, y_pred, color=test_color, s=30, label='Test set')\n",
    "\n",
    "ax.plot([min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        [min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        color='black', linestyle='--')\n",
    "\n",
    "ax.set_ylabel('Predicted values', fontsize=22)\n",
    "ax.set_xlabel('True Values', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.legend(fontsize=18, frameon = False, loc='upper left')\n",
    "\n",
    "fig.set_dpi(500)\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\pred_evap_parity_DT_10_20.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity - RF\n",
    "colors = cm.vik\n",
    "train_color_index = 0.1\n",
    "test_color_index = 0.87\n",
    "train_color = colors(train_color_index)\n",
    "test_color = colors(test_color_index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(y_train, y_pred_train, color=train_color, s=30, label='Train set')\n",
    "\n",
    "ax.scatter(y_test, y_pred, color=test_color, s=30, label='Test set')\n",
    "\n",
    "ax.plot([min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        [min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        color='black', linestyle='--')\n",
    "\n",
    "ax.set_ylabel('Predicted values', fontsize=22)\n",
    "ax.set_xlabel('True Values', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.legend(fontsize=18, frameon = False, loc='upper left')\n",
    "\n",
    "fig.set_dpi(500)\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\pred_evap_parity_RF_10_20.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity - XGBoost\n",
    "colors = cm.vik\n",
    "train_color_index = 0.1\n",
    "test_color_index = 0.87\n",
    "train_color = colors(train_color_index)\n",
    "test_color = colors(test_color_index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(y_train, y_pred_train, color=train_color, s=30, label='Train set')\n",
    "\n",
    "ax.scatter(y_test, y_pred, color=test_color, s=30, label='Test set')\n",
    "\n",
    "ax.plot([min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        [min(min(y_train.values), min(y_test.values)), max(max(y_train.values), max(y_test.values))],\n",
    "        color='black', linestyle='--')\n",
    "\n",
    "ax.set_ylabel('Predicted values', fontsize=22)\n",
    "ax.set_xlabel('True Values', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.legend(fontsize=18, frameon = False, loc='upper left')\n",
    "\n",
    "fig.set_dpi(500)\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\pred_evap_parity_XGBoost_10_20.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3 - 20 hours to end database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of separated sizes, creating the seed area\n",
    "Data_raw_20_e ['Seed crystal mm2'] = (Data_raw_20_e['Seed Size A (mm)']*\n",
    "                                      Data_raw_20_e['Seed Size B (mm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing non-desired features from the raw data - categorical, constants, values obtained in the end and imaging related features\n",
    "Data_raw_20_e = Data_raw_20_e.drop(['Hotplate', 'Last Syringe Mass (g)',\n",
    "                            'Last Solution Mass (g)', 'Last Total Mass (g)',\n",
    "                            'All Deposited Crystals (g)', 'Total Infusion (g)', 'Total Evaporation (g)', \n",
    "                            'Estimated Last Concentration (wt.%)', 'Hotplate Temperature (oC)',\n",
    "                            'Syringe Diameter (mm)', 'Imaging Width (pixel)',\n",
    "                            'Imaging Height (pixel)', 'Shot Interval (sec)', 'Mask Radius (pixel)',\n",
    "                            'Scale (pixel/mm2)', 'B Bottom Threshold', 'G Bottom Threshold',\n",
    "                            'R Bottom Threshold', 'B Top Threshold', 'G Top Threshold',\n",
    "                            'R Top Threshold', 'L Smoothing Parameters 1',\n",
    "                            'L Smoothing Parameters 2', 'G Smoothing Parameters 1',\n",
    "                            'G Smoothing Parameters 2', 'Smoothed Growth Rate (mm/h)', 'Smoothed Length (mm)',\n",
    "                            'source', 'Unnamed: 0', 'source.1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot\n",
    "plt.figure(figsize=(10,8))\n",
    "heatmap = sns.heatmap(Data_raw_20_e.corr(), vmin=-1, vmax=1, annot=False, \n",
    "                    cmap= cm.vik, #'viridis', #cmocean.cm.matter,\n",
    "                    square=True)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(),\n",
    "                   rotation=45,\n",
    "                   horizontalalignment='right')\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\corr_plot_20_end_1st.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non-desired features from the raw data - correlated and redundant features\n",
    "Data_raw_20_e = Data_raw_20_e.drop(['Crystal Size A (mm)', 'Crystal Size B (mm)', 'Crystal Size C (mm)', 'Number of Crystals',\n",
    "                            'integral e', 'Length (mm)', 'Kp', 'Ki', 'Kd', 'de/dt', 'e(t)',\n",
    "                            'Initial Infusion Rate (mL/h)', 'Total Infusion (mL)',\n",
    "                            'Initial Syringe Mass (g)', 'Initial Total Mass (g)',\n",
    "                            'Est-Mass (g)', 'Initial Concentration (wt.%)', 'Estimated Evaporation Rate (g/h)',\n",
    "                            'Seed crystal mm2', 'Seed Size A (mm)', 'Seed Size B (mm)', 'Seed Size C (mm)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_final_20_e = Data_raw_20_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "Data_final_20_e = Data_final_20_e.rename(columns=\n",
    "                                 {'Initial Solution Mass (g)':'Initial_Solution_Mass',\n",
    "                                  'Room Temperature (oC)':'Room_Temperature', \n",
    "                                  'Humidity (RH%)': 'Humidity',\n",
    "                                  'Evaporation Rate (g/h)': 'Evaporation_Rate',\n",
    "                                  'Ideal Growth Rate (mm/h)': 'Ideal_Growth_Rate', \n",
    "                                  'Time (h)': 'Time', \n",
    "                                  'Infusion Rate (mL/h)': 'Infusion_Rate',\n",
    "                                  'Area (mm2)': 'Area', \n",
    "                                  'Growth Rate (mm/h)': 'Growth_Rate', \n",
    "                                  'Estimated Concentration (wt.%)': 'Estimated_Concentration'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New order of columns\n",
    "new_order = ['Initial_Solution_Mass', 'Room_Temperature', 'Humidity',\n",
    "       'Evaporation_Rate', 'Ideal_Growth_Rate', 'Infusion_Rate', 'Time',\n",
    "       'Area', 'Growth_Rate', 'Estimated_Concentration']\n",
    "\n",
    "Data_final_20_e = Data_final_20_e.reindex(columns=new_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NA values and negative values from evaporation rate and estimated concentration\n",
    "Data_final_20_e = Data_final_20_e.dropna()\n",
    "Data_final_20_e = Data_final_20_e[Data_final_20_e['Evaporation_Rate'] >= 0]\n",
    "Data_final_20_e = Data_final_20_e[Data_final_20_e['Estimated_Concentration'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot\n",
    "plt.figure(figsize=(10,8))\n",
    "heatmap = sns.heatmap(Data_final_20_e.corr(), vmin=-1, vmax=1, annot=False, \n",
    "                    cmap= cm.vik,\n",
    "                    square=True)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(),\n",
    "                   rotation=45,\n",
    "                   horizontalalignment='right')\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\corr_plot_20_end_2nd.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models development/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from hyperopt import hp, fmin, tpe, space_eval, Trials\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x and y subsets\n",
    "x_20_e = Data_final_20_e.drop(['Evaporation_Rate'], axis=1)\n",
    "y_20_e = Data_final_20_e[['Evaporation_Rate']]\n",
    "\n",
    "np.random.seed(100)\n",
    "X_train_20_e, X_test_20_e, y_train_20_e, y_test_20_e = train_test_split(x_20_e, y_20_e, test_size=0.25, random_state=25) # 75% training and 25% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### to optimize hyperparameters, do the lines below\n",
    "# Define the search space\n",
    "space_20_e = {\n",
    "    'max_depth': hp.choice('max_depth', range(1, 800)),\n",
    "    'max_features': hp.choice('max_features', [1.0, 'sqrt']),\n",
    "    'max_leaf_nodes': hp.choice('max_leaf_nodes', range(2, 500)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 10)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'min_weight_fraction_leaf': hp.choice('min_weight_fraction_leaf', [0.1])\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    dt_20_e = DecisionTreeRegressor(**params)\n",
    "    scores = cross_val_score(dt_20_e, X_train_20_e, y_train_20_e, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean()) \n",
    "    return rmse\n",
    "\n",
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best_20_e = fmin(fn=objective, space=space_20_e, algo=tpe.suggest, max_evals=200, trials=trials)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_20_e = space_eval(space, best_20_e)\n",
    "\n",
    "# Create a Decision Tree regressor with the best hyperparameters\n",
    "dt_20_e = DecisionTreeRegressor(**best_params)\n",
    "scores_20_e = cross_val_score(dt_20_e, X_train_20_e, y_train_20_e, cv=cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "dt_20_e.fit(X_train_20_e, y_train_20_e)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred_20_e = dt_20_e.predict(X_test_20_e)\n",
    "y_pred_train_20_e = dt_20_e.predict(X_train_20_e)\n",
    "\n",
    "print(best_params_20_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimized model for decision trees\n",
    "# Create the parameter grid based on the results of random search - using hyperopt   --- decision trees\n",
    "best_params_20_e = {\n",
    "              'max_depth': 22, \n",
    "              'max_features':1.0, \n",
    "              'max_leaf_nodes': 119,\n",
    "              'min_weight_fraction_leaf': 0.1, \n",
    "              'min_samples_leaf': 7,\n",
    "              'min_samples_split': 8 \n",
    "}\n",
    "# Create a Decision Tree regressor with the best hyperparameters\n",
    "dt_20_e = DecisionTreeRegressor(**best_params_20_e)\n",
    "dt_20_e.fit(X_train_20_e, y_train_20_e)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred_20_e = dt_20_e.predict(X_test_20_e)\n",
    "y_pred_train_20_e = dt_20_e.predict(X_train_20_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "MAE_train_dt_20_e = pd.DataFrame(mean_absolute_error(y_train_20_e, y_pred_train_20_e, multioutput='raw_values'))\n",
    "RMSE_train_dt_20_e = pd.DataFrame(np.sqrt(mean_squared_error(y_train_20_e, y_pred_train_20_e, multioutput='raw_values')))\n",
    "R2_train_dt_20_e = pd.DataFrame(r2_score(y_train_20_e, y_pred_train_20_e, multioutput='raw_values'))\n",
    "train_metrics_dt_20_e = pd.concat([MAE_train_dt_20_e, RMSE_train_dt_20_e, R2_train_dt_20_e], axis='columns')\n",
    "train_metrics_dt_20_e.columns = ['MAE_train', 'RMSE_train', 'R2_train']\n",
    "print(train_metrics_dt_20_e)\n",
    "\n",
    "# Test metrics\n",
    "MAE_test_dt_20_e = pd.DataFrame(mean_absolute_error(y_test_20_e, y_pred_20_e, multioutput='raw_values'))\n",
    "RMSE_test_dt_20_e = pd.DataFrame(np.sqrt(mean_squared_error(y_test_20_e, y_pred_20_e, multioutput='raw_values')))\n",
    "R2_test_dt_20_e = pd.DataFrame(r2_score(y_test_20_e, y_pred_20_e, multioutput='raw_values'))\n",
    "test_metrics_dt_20_e = pd.concat([MAE_test_dt_20_e, RMSE_test_dt_20_e, R2_test_dt_20_e], axis='columns')\n",
    "test_metrics_dt_20_e.columns = ['MAE_test', 'RMSE_test', 'R2_test']\n",
    "print(test_metrics_dt_20_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### to optimize hyperparameters, do the lines below\n",
    "# Define the search space\n",
    "space_20_e = {\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False]),\n",
    "    'max_depth': hp.choice('max_depth', range(1, 100)),\n",
    "    'max_features': hp.choice('max_features', [1.0, 'sqrt']),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 10)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 500))\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    rf_20_e = RandomForestRegressor(**params)\n",
    "    scores = cross_val_score(rf_20_e, X_train_20_e, y_train_20_e, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean())\n",
    "    return rmse\n",
    "\n",
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best_20_e = fmin(fn=objective, space=space_20_e, algo=tpe.suggest, max_evals=2, trials=trials)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_20_e = space_eval(space_20_e, best_20_e)\n",
    "\n",
    "# Create a Random Forest regressor with the best hyperparameters\n",
    "rf_20_e = RandomForestRegressor(**best_params_20_e)\n",
    "scores = cross_val_score(rf_20_e, X_train_20_e, y_train_20_e, scoring='neg_mean_squared_error')\n",
    "\n",
    "rf_20_e.fit(X_train_20_e, y_train_20_e)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred_20_e = rf_20_e.predict(X_test_20_e)\n",
    "\n",
    "\n",
    "print(best_params_20_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest optimized\n",
    " #### after defined the search space\n",
    "best_params_20_e = {\n",
    "    'bootstrap': False,\n",
    "    'max_depth': 30,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 2,\n",
    "    'min_samples_split': 4,\n",
    "    'n_estimators': 250,\n",
    "}\n",
    "\n",
    "rf_20_e = RandomForestRegressor(**best_params_20_e)\n",
    "rf_20_e.fit(X_train_20_e, np.ravel(y_train_20_e)) \n",
    "\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred_20_e = rf_20_e.predict(X_test_20_e)\n",
    "y_pred_train_20_e = rf_20_e.predict(X_train_20_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "MAE_train_rf_20_e = pd.DataFrame(mean_absolute_error(y_train_20_e, y_pred_train_20_e, multioutput='raw_values'))\n",
    "RMSE_train_rf_20_e = pd.DataFrame(np.sqrt(mean_squared_error(y_train_20_e, y_pred_train_20_e, multioutput='raw_values')))\n",
    "R2_train_rf_20_e = pd.DataFrame(r2_score(y_train_20_e, y_pred_train_20_e, multioutput='raw_values'))\n",
    "train_metrics_rf_20_e = pd.concat([MAE_train_rf_20_e, RMSE_train_rf_20_e, R2_train_rf_20_e], axis='columns')\n",
    "train_metrics_rf_20_e.columns = ['MAE_train', 'RMSE_train', 'R2_train']\n",
    "print(train_metrics_rf_20_e)\n",
    "\n",
    "# Test metrics\n",
    "MAE_test_rf_20_e = pd.DataFrame(mean_absolute_error(y_test_20_e, y_pred_20_e, multioutput='raw_values'))\n",
    "RMSE_test_rf_20_e = pd.DataFrame(np.sqrt(mean_squared_error(y_test_20_e, y_pred_20_e, multioutput='raw_values')))\n",
    "R2_test_rf_20_e = pd.DataFrame(r2_score(y_test_20_e, y_pred_20_e, multioutput='raw_values'))\n",
    "test_metrics_rf_20_e = pd.concat([MAE_test_rf_20_e, RMSE_test_rf_20_e, R2_test_rf_20_e], axis='columns')\n",
    "test_metrics_rf_20_e.columns = ['MAE_test', 'RMSE_test', 'R2_test']\n",
    "print(test_metrics_rf_20_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### to optimize hyperparameters, do the lines below\n",
    "# Define the search space\n",
    "space_20_e = {\n",
    "    'max_depth': hp.choice('max_depth', range(5, 50)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.03, 0.08),\n",
    "    'n_estimators': hp.choice('n_estimators', range(400,1000)),\n",
    "    'gamma': hp.uniform('gamma', 0.3, 0.7),\n",
    "    'min_child_weight': hp.choice('min_child_weight', range(5, 15)),\n",
    "    'subsample': hp.uniform('subsample', 0.1, 0.8),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.8)\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    xgb_reg_20_e = xgb.XGBRegressor(**params, random_state=42)\n",
    "    scores = cross_val_score(xgb_reg_20_e, X_train_20_e, y_train_20_e, cv=cv, scoring='neg_mean_squared_error')\n",
    "    #rmse = np.sqrt(-scores.mean())  # Negative mean squared error to minimize\n",
    "    mean_r2 = scores.mean()\n",
    "    return -mean_r2 \n",
    "\n",
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best_20_e = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_20_e = space_eval(space_20_e, best_20_e)\n",
    "\n",
    "# Create a Decision Tree regressor with the best hyperparameters\n",
    "xgb_20_e = xgb.XGBRegressor(**best_params_20_e)\n",
    "scores = cross_val_score(xgb_20_e, X_train_20_e, y_train_20_e, cv=cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "xgb.fit(X_train_20_e, y_train_20_e)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred_20_e = xgb.predict(X_test_20_e)\n",
    "y_pred_train_20_e = xgb.predict(X_train_20_e)\n",
    "\n",
    "print(best_params_20_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost optimized with hyperopt\n",
    "\n",
    "best_params_20_e = {\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.04,\n",
    "    'n_estimators': 1000,\n",
    "    'gamma': 0.1,\n",
    "    'min_child_weight': 10,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'lambda': 1,\n",
    "    'alpha': 0\n",
    "}\n",
    "\n",
    "# Create a Random Forest regressor with the best hyperparameters - hyperopt\n",
    "xgb_20_e = xgb.XGBRegressor(**best_params_20_e)\n",
    "xgb_20_e.fit(X_train_20_e, y_train_20_e)\n",
    "\n",
    "# Prediction on test set\n",
    "y_pred_20_e = xgb_20_e.predict(X_test_20_e)\n",
    "y_pred_train_20_e = xgb_20_e.predict(X_train_20_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "MAE_train_xgb_20_e = pd.DataFrame(mean_absolute_error(y_train_20_e, y_pred_train_20_e, multioutput='raw_values'))\n",
    "RMSE_train_xgb_20_e = pd.DataFrame(np.sqrt(mean_squared_error(y_train_20_e, y_pred_train_20_e, multioutput='raw_values')))\n",
    "R2_train_xgb_20_e = pd.DataFrame(r2_score(y_train_20_e, y_pred_train_20_e, multioutput='raw_values'))\n",
    "train_metrics_xgb_20_e = pd.concat([MAE_train_xgb_20_e, RMSE_train_xgb_20_e, R2_train_xgb_20_e], axis='columns')\n",
    "train_metrics_xgb_20_e.columns = ['MAE_train', 'RMSE_train', 'R2_train']\n",
    "print(train_metrics_xgb_20_e)\n",
    "\n",
    "# Test metrics\n",
    "MAE_test_xgb_20_e = pd.DataFrame(mean_absolute_error(y_test_20_e, y_pred_20_e, multioutput='raw_values'))\n",
    "RMSE_test_xgb_20_e = pd.DataFrame(np.sqrt(mean_squared_error(y_test_20_e, y_pred_20_e, multioutput='raw_values')))\n",
    "R2_test_xgb_20_e = pd.DataFrame(r2_score(y_test_20_e, y_pred_20_e, multioutput='raw_values'))\n",
    "test_metrics_xgb_20_e = pd.concat([MAE_test_xgb_20_e, RMSE_test_xgb_20_e, R2_test_xgb_20_e], axis='columns')\n",
    "test_metrics_xgb_20_e.columns = ['MAE_test', 'RMSE_test', 'R2_test']\n",
    "print(test_metrics_xgb_20_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP and Features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features importance by permutation\n",
    "result = permutation_importance(dt_20_e, X_test_20_e, y_test_20_e, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices]\n",
    "sorted_feature_names = [X_test_20_e.columns[i] for i in indices]\n",
    "\n",
    "n_colors = len(sorted_importances)  \n",
    "colors = [cm.vik(i / (n_colors - 1)) for i in range(n_colors)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Permutation Feature Importance\")\n",
    "sns.barplot(x=sorted_importances, y=sorted_feature_names, palette=colors)\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\feat_imp_DT_20_end.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP plot\n",
    "\n",
    "N = 1000\n",
    "X_sample_20_e = X_test_20_e.sample(n=N, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(dt_20_e, data=X_test_20_e)\n",
    "\n",
    "shap_values = explainer.shap_values(X_sample_20_e, check_additivity=False)\n",
    "\n",
    "feature_names = X_test_20_e.columns.astype(str)\n",
    "\n",
    "shap.summary_plot(shap_values, X_sample_20_e, feature_names=feature_names, show=False)\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\Shap_DT_20_end.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features importance by permutation\n",
    "result = permutation_importance(rf_20_e, X_test_20_e, y_test_20_e, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices]\n",
    "sorted_feature_names = [X_test_20_e.columns[i] for i in indices]\n",
    "\n",
    "n_colors = len(sorted_importances)\n",
    "colors = [cm.vik(i / (n_colors - 1)) for i in range(n_colors)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Permutation Feature Importance\")\n",
    "sns.barplot(x=sorted_importances, y=sorted_feature_names, palette=colors)\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\feat_imp_RF_20_end.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP plot - RF\n",
    "\n",
    "N = 1000\n",
    "X_sample_20_e = X_test_20_e.sample(n=N, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(rf_20_e, data=X_test_20_e)\n",
    "\n",
    "shap_values = explainer.shap_values(X_sample_20_e, check_additivity=False)\n",
    "\n",
    "feature_names = X_test_20_e.columns.astype(str)\n",
    "\n",
    "shap.summary_plot(shap_values, X_sample_20_e, feature_names=feature_names, show=False)\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\Shap_RF_20_end.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features importance by permutation\n",
    "result = permutation_importance(xgb_20_e, X_test_20_e, y_test_20_e, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices]\n",
    "sorted_feature_names = [X_test_20_e.columns[i] for i in indices]\n",
    "\n",
    "n_colors = len(sorted_importances)\n",
    "colors = [cm.vik(i / (n_colors - 1)) for i in range(n_colors)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Permutation Feature Importance\")\n",
    "sns.barplot(x=sorted_importances, y=sorted_feature_names, palette=colors)\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\feat_imp_XGB_20_end.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP plot\n",
    "\n",
    "N = 1000\n",
    "X_sample_20_e = X_test_20_e.sample(n=N, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb_20_e, data=X_test_20_e)\n",
    "\n",
    "shap_values = explainer.shap_values(X_sample_20_e, check_additivity=False)\n",
    "\n",
    "feature_names = X_test_20_e.columns.astype(str)\n",
    "\n",
    "shap.summary_plot(shap_values, X_sample_20_e, feature_names=feature_names, show=False)\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\Shap_XGB_20_end.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parity plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity for DT\n",
    "\n",
    "colors = cm.vik\n",
    "train_color_index = 0.1\n",
    "test_color_index = 0.87\n",
    "train_color = colors(train_color_index)\n",
    "test_color = colors(test_color_index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(y_train_20_e, y_pred_train_20_e, color=train_color, s=30, label='Train set')\n",
    "ax.scatter(y_test_20_e, y_pred_20_e, color=test_color, s=30, label='Test set')\n",
    "\n",
    "ax.plot([min(min(y_train_20_e.values), min(y_test_20_e.values)), max(max(y_train_20_e.values), max(y_test_20_e.values))],\n",
    "        [min(min(y_train_20_e.values), min(y_test_20_e.values)), max(max(y_train_20_e.values), max(y_test_20_e.values))],\n",
    "        color='black', linestyle='--')\n",
    "\n",
    "ax.set_ylabel('Predicted values', fontsize=22)\n",
    "ax.set_xlabel('True Values', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "ax.legend(fontsize=18, frameon = False, loc='upper left')\n",
    "\n",
    "fig.set_dpi(500)\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\pred_evap_parity_DT_20_end.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity - RF\n",
    "colors = cm.vik\n",
    "train_color_index = 0.1\n",
    "test_color_index = 0.87\n",
    "train_color = colors(train_color_index)\n",
    "test_color = colors(test_color_index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(y_train_20_e, y_pred_train_20_e, color=train_color, s=30, label='Train set')\n",
    "ax.scatter(y_test_20_e, y_pred_20_e, color=test_color, s=30, label='Test set')\n",
    "\n",
    "ax.plot([min(min(y_train_20_e.values), min(y_test_20_e.values)), max(max(y_train_20_e.values), max(y_test_20_e.values))],\n",
    "        [min(min(y_train_20_e.values), min(y_test_20_e.values)), max(max(y_train_20_e.values), max(y_test_20_e.values))],\n",
    "        color='black', linestyle='--')\n",
    "\n",
    "ax.set_ylabel('Predicted values', fontsize=22)\n",
    "ax.set_xlabel('True Values', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "ax.legend(fontsize=18, frameon = False, loc='upper left')\n",
    "\n",
    "fig.set_dpi(500)\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\pred_evap_parity_RF_20_end.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity - XGBoost\n",
    "\n",
    "colors = cm.vik\n",
    "train_color_index = 0.1\n",
    "test_color_index = 0.87\n",
    "train_color = colors(train_color_index)\n",
    "test_color = colors(test_color_index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(y_train_20_e, y_pred_train_20_e, color=train_color, s=30, label='Train set')\n",
    "\n",
    "ax.scatter(y_test_20_e, y_pred_20_e, color= test_color, s=30, label='Test set')\n",
    "\n",
    "ax.plot([min(min(y_train_20_e.values), min(y_test_20_e.values)), max(max(y_train_20_e.values), max(y_test_20_e.values))],\n",
    "        [min(min(y_train_20_e.values), min(y_test_20_e.values)), max(max(y_train_20_e.values), max(y_test_20_e.values))],\n",
    "        color='black', linestyle='--')\n",
    "\n",
    "ax.set_ylabel('Predicted values', fontsize=22)\n",
    "ax.set_xlabel('True Values', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "ax.legend(fontsize=18, frameon = False, loc='upper left')\n",
    "\n",
    "fig.set_dpi(500)\n",
    "\n",
    "file_name = r'Y:\\36 TP\\MAPbBr3\\Paper ML crystal\\pred_evap_parity_XGBoost_20_end.png'\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name, dpi=500)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
